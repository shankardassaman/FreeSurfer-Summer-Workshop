{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "This is a guided tutorial on how to extract data from the DICOM-SERVER at CFMI unto your own machine. This notebook assumes you have the following already set up:\n",
    "\n",
    "    1. An account on the CFMI server\n",
    "    2. Proper permissions to view raw data\n",
    "    3. A working copy of the ssh-tools repository\n",
    "    4. A mounted network volume that points to the raw dicoms (see below for more info)\n",
    "    5. GNU Parallel installed on your machine\n",
    "\n",
    "Assuming you have the required prerequesities already satisfied you can get started by giong to https://github.com/seldamat/dicom-tools and forking it repository to your account\n",
    "\n",
    "Next clone your fork to a place on your computer (you can change the code to choose your home directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/Users/shad/dicom-tools'...\n",
      "remote: Counting objects: 27, done.\u001b[K\n",
      "remote: Total 27 (delta 0), reused 0 (delta 0), pack-reused 27\u001b[K\n",
      "Unpacking objects: 100% (27/27), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# Define your github user name here\n",
    "github_un='seldamat'\n",
    "# Define place you want to put it\n",
    "clone_here='/Volumes/CFMI-CFS/opt/dicom-tools'\n",
    "# If directory doesn't exist, then Clone!\n",
    "[ ! -d ${clone_here} ] && git clone https://github.com/${github_un}/dicom-tools.git ${clone_here}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check what's inside this new repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxr-xr-x   5 staff   170 Jun 28 10:29 .\n",
      "drwxr-xr-x+ 92 staff  3128 Jun 28 10:29 ..\n",
      "drwxr-xr-x  12 staff   408 Jun 28 10:29 .git\n",
      "-rw-r--r--   1 staff    74 Jun 28 10:29 README.md\n",
      "-rwxr-xr-x   1 staff 17261 Jun 28 10:29 fetch-dicom\n"
     ]
    }
   ],
   "source": [
    "cd ${clone_here}\n",
    "ls -alg ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the --help argument to get some useful help information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "./fetch-dicom --help\n",
    "\n",
    "Usage :: fetch-dicom [-h|--help] [-r|--rawdatadir PATH] [-o|--outputdir PATH] [-s|--subject] \n",
    "[-y|--year YYYY] [-m|--month MM] [-d|--day DD] [-t|--tasks LIST]\n",
    "\n",
    "Search for Seimens .IMA files in the raw data directory for a subject scanned on YYYY-MM-DD. User can specify tasks \n",
    "for extraction, or leave blank to extract everything. Dicoms are placed in the output directory.\n",
    "\n",
    "Required Arguments\n",
    "-r  --rawdatadir path to dicoms (subdirectory tree must follow ./YYYY/MM/DD)\n",
    "-o  --outputdir extract dicoms here\t       \n",
    "-s  --subject subject ID\n",
    "-y  --year year of scan date\n",
    "-m  --month month of scan date\n",
    "-d  --day day of scan date\n",
    "\n",
    "Optional Arguments \t      \n",
    "-t  --tasks list of tasks to extract data for (series description)\n",
    "-prv --private omit identifiers from meta data text file (will still be present in dcm headers)\n",
    "\n",
    "Other Arguments\n",
    "-h  --help displays this message\n",
    "```\n",
    "\n",
    "The raw data directory is set inside fetch dicom by default to: \n",
    "```bash\n",
    "/Volumes/CFMI-CFS/mnt/CFMI-DICOMS/\n",
    "```\n",
    "This may be different on your computer. I can help you get set up if you don't know what this means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may not know what the subject ID is.. but we do know the days that we scanned! We can use this to find our data.\n",
    "```bash\n",
    "./fetch-dicom -y 2017 -m 06 -d 26 -r '/Volumes/CFMI-CFS/mnt/CFMI-DICOMS'\n",
    "\n",
    "Parsing Metadata for Studies Performed on 2017-06-26...ðŸ—’  3 Studies Found...\n",
    "Printing List of Subjects Scanned on This Day\n",
    "\n",
    " â™” Study PI: Turkeltaub \n",
    " âœŽ SID: QNJ\n",
    " âœŽ Age: 064Y\n",
    " âœŽ Sex: M \n",
    " âœŽ Wgt: 91.1720779677 \n",
    " âœŽ Series (In Order Acquired) â€£ Session Start Time: 11:25:33\n",
    "     1\t \tPA_Multi Plane 50Slice Loc\n",
    "     2\t \tSiemens_MPRAGE\n",
    "     3\t \tep2d_diff 80dir iPAT\n",
    "     4\t \tep2d_diff 80dir iPAT_FA \n",
    "     5\t \tep2d_diff 80dir iPAT_ColFA\n",
    "     6\t \tMoCoSeries\n",
    "     7\t \tep2d_pcasl_UI_PHC \n",
    "\n",
    " â™” Study PI: VanMeter \n",
    " âœŽ SID: FSSUM-1\n",
    " âœŽ Age: 022Y\n",
    " âœŽ Sex: F \n",
    " âœŽ Wgt: 63.502939878\n",
    " âœŽ Series (In Order Acquired) â€£ Session Start Time: 13:11:08\n",
    "     1\t \tMulti Plane 50Slice Loc \n",
    "     2\t \tSiemens_MPRAGE\n",
    "     3\t \tSiemens_MPRAGE\n",
    "\n",
    " â™” Study PI: <unknown>\n",
    " âœŽ SID: LM-LOKI\n",
    " âœŽ Age: 006Y\n",
    " âœŽ Sex: M \n",
    " âœŽ Wgt: 9.2 \n",
    " âœŽ Series (In Order Acquired) â€£ Session Start Time: 17:09:17\n",
    "     1\t \tPA_Multi Plane 50Slice Loc\n",
    "     2\t \tSiemens_MPRAGE\n",
    "     3\t \tPA_Multi Plane 50Slice Loc\n",
    "     4\t \tSiemens_MPRAGE\n",
    "     5\t \tPA_Multi Plane 50Slice Loc\n",
    "     6\t \tSiemens_MPRAGE\n",
    "     7\t \t<MPR Range_Native (MR)_Anatomy[1]>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a directory to stick our data in and extract the data\n",
    "```bash\n",
    "fssw_folder='~/Documents/GitHub/FreeSurfer-Summer-Workshop'\n",
    "datafolder=\"${fssw_folder}/mris/hydration-experiment/dicoms/baseline-day/FSSUM-1\"\n",
    "mkdir -p ${folder}\n",
    "fetch-dicom -y 2017 -m 06 -d 26 -s 'FSSUM-1' -o ${datafolder} -r '/Volumes/CFMI-CFS/mnt/CFMI-DICOMS'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the same procedure to check that the data is present on the second day\n",
    "```bash\n",
    "./fetch-dicom -y 2017 -m 06 -d 27\n",
    "\n",
    "Parsing Metadata for Studies Performed on 2017-06-27..ðŸ—’  2 Studies Found...\n",
    "Printing List of Subjects Scanned on This Day\n",
    "\n",
    " â™” Study PI: Mandelblatt\n",
    " âœŽ SID: 108880474\n",
    " âœŽ Age: 076Y\n",
    " âœŽ Sex: F \n",
    " âœŽ Wgt: 61.6885701672 \n",
    " âœŽ Series (In Order Acquired) â€£ Session Start Time: 08:57:52\n",
    "     1\t \tMulti Plane 50Slice Loc \n",
    "     2\t \tMPRAGE-ADNI \n",
    "     3\t \tgre_field_mapping_88\n",
    "     4\t \tMoCoSeries\n",
    "     5\t \tep2d_pace_vv2bk \n",
    "     6\t \tMoCoSeries\n",
    "     7\t \tep2d_pace_sc-encode1\n",
    "     8\t \tMoCoSeries\n",
    "     9\t \tep2d_pace_sc-recognition1 \n",
    "    10\t \tMoCoSeries\n",
    "    11\t \tep2d_pace_rest\n",
    "    12\t \tt2_tirm_tra_dark-fluid_3mm\n",
    "    13\t \tt2_spc_irprep_SAG_p2_dark-fluid_100pfov \n",
    "    14\t \tep2d_diff_55dir \n",
    "    15\t \tep2d_diff_55dir_TRACEW\n",
    "    16\t \tep2d_diff_55dir_FA\n",
    "    17\t \tep2d_diff_55dir_ColFA \n",
    "\n",
    " â™” Study PI: VanMeter \n",
    " âœŽ SID: FSSUM-1\n",
    " âœŽ Age: 022Y\n",
    " âœŽ Sex: F \n",
    " âœŽ Wgt: 63.502939878\n",
    " âœŽ Series (In Order Acquired) â€£ Session Start Time: 11:55:22\n",
    "     1\t \tMulti Plane 50Slice Loc \n",
    "     2\t \tSiemens_MPRAGE\n",
    "     3\t \tMulti Plane 50Slice Loc \n",
    "     4\t \tSiemens_MPRAGE\n",
    "     5\t \tt2_spc_sag_p2_iso \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract this data as well\n",
    "\n",
    "```bash\n",
    "datafolder=\"${fssw_folder}/mris/hydration-experiment/dicoms/dehydrated-day/FSSUM-1\"\n",
    "\n",
    "mkdir -p ${folder}\n",
    "\n",
    "fetch-dicom -y 2017 -m 06 -d 26 -s 'FSSUM-1' -o ${datafolder} -r '/Volumes/CFMI-CFS/mnt/CFMI-DICOMS'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Conversion\n",
    "\n",
    "The data that we have extracted is in a raw DICOM format (.IMA) and must be converted to the standard we use for neuroimaging analysis (.nii). We also want to compress our files to minimize the amount of space we are using (.nii.gz). \n",
    "\n",
    "First let's begin by moving to our workshop `mris` folder and creating a few folders to keep everything in.\n",
    "\n",
    "```bash\n",
    "cd ${fssw_folder}/mris\n",
    "mkdir -p nii.gz/baseline-day/FSSUM-1    #type of file/experiment-day/subjectID\n",
    "mkdir -p nii.gz/dehydrated-day/FSSUM-1\n",
    "```\n",
    "\n",
    "To convert the files, we need to use a converter. Here I have chosen the dcm2niix software as my preferred converter. You can obtain this converter by cloning it from github. Once you have it installed you can type\n",
    "\n",
    "```bash\n",
    "[ ! -d '~/bin/dcm2niix' ] && git clone https://github.com/rordenlab/dcm2niix ~/bin/dcm2niix\n",
    "cd ~/bin/dc2mniix\n",
    "```\n",
    "\n",
    "The conversion is pretty straightforward. Type the following to get usage information\n",
    "\n",
    "```bash\n",
    "./dcm2niix\n",
    "\n",
    "Compression will be faster with /usr/local/bin/pigz\n",
    "Chris Rorden's dcm2niiX version 7July2016 (64-bit)\n",
    "usage: dcm2niix [options] <in_folder>\n",
    " Options :\n",
    "  -b : BIDS sidecar (y/n, default n)\n",
    "  -f : filename (%c=comments %f=folder name %i ID of patient %m=manufacturer %n=name of patient %p=protocol, %q=sequence %s=series, %t=time; default '%q-%p')\n",
    "  -h : show help\n",
    "  -m : merge 2D slices from same series regardless of study time, echo, coil, orientation, etc. (y/n, default n)\n",
    "  -o : output directory (omit to save to input folder)\n",
    "  -s : single file mode, do not convert other images in folder (y/n, default n)\n",
    "  -t : text notes includes private patient details (y/n, default n)\n",
    "  -v : verbose (y/n, default n)\n",
    "  -x : crop (y/n, default n)\n",
    "  -z : gz compress images (y/i/n, default y) [y=pigz, i=internal, n=no]\n",
    " Defaults file : /Users/shad/.dcm2nii.ini\n",
    " Examples :\n",
    "  dcm2niix /Users/chris/dir\n",
    "  dcm2niix -o /users/cr/outdir/ -z y ~/dicomdir\n",
    "  dcm2niix -f mystudy%s ~/dicomdir\n",
    "  dcm2niix -o \"~/dir with spaces/dir\" ~/dicomdir\n",
    "```\n",
    "\n",
    "To convert our data from the experiments we ran, type this:\n",
    "\n",
    "```bash\n",
    "cd ${fssw_folder}/mris\n",
    "dcm2niix -o nii.gz/baseline-day/FSSUM-1 dicoms/baseline-day/FSSUM-1/\n",
    "dcm2niix -o nii.gz/dehydrated-day/FSSUM-1 dicoms/dehydrated-day/FSSUM-1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing recon-all for Reconstruction\n",
    "\n",
    "First we need to set our subjects directory and import the data\n",
    "\n",
    "```bash\n",
    "cd ${fssw_folder}/mris\n",
    "mkdir ./fs\n",
    "cd fs\n",
    "export SUBJECTS_DIR=$(pwd)\n",
    "\n",
    "# Day 1\n",
    "## T1s\n",
    "recon-all -i '../mris/hydration-experiment/nii.gz/baseline-day/FSSUM-1/GR_IR-Siemens_MPRAGE.nii.gz' -s 'sub.01.bl.01'\n",
    "recon-all -i '../mris/hydration-experiment/nii.gz/baseline-day/FSSUM-1/GR_IR-Siemens_MPRAGEa.nii.gz' -s 'sub.01.bl.02'\n",
    "\n",
    "\n",
    "# Day 2\n",
    "## T1-1\n",
    "recon-all -i '../mris/hydration-experiment/nii.gz/dehydrated-day/FSSUM-1/GR_IR-Siemens_MPRAGE.nii.gz' -s 'sub.01.dh.01'\n",
    "## T1-2\n",
    "recon-all -i '../mris/hydration-experiment/nii.gz/dehydrated-day/FSSUM-1/GR_IR-Siemens_MPRAGEa.nii.gz' -s 'sub.01.dh.02'\n",
    "## T2-1\n",
    "recon-all -i '../mris/hydration-experiment/nii.gz/dehydrated-day/FSSUM-1/GR_IR-Siemens_MPRAGE.nii.gz' -T2 '../mris/hydration-experiment/nii.gz/dehydrated-day/FSSUM-1/SE-t2_spc_sag_p2_iso.nii.gz' -s 'sub.01.dh.01t2'\n",
    "## T2-2\n",
    "recon-all -i '../mris/hydration-experiment/nii.gz/dehydrated-day/FSSUM-1/GR_IR-Siemens_MPRAGEa.nii.gz' -T2 '../mris/hydration-experiment/nii.gz/dehydrated-day/FSSUM-1/SE-t2_spc_sag_p2_iso.nii.gz' -s 'sub.01.dh.02t2'\n",
    "```\n",
    "\n",
    "\n",
    "Now we can run the recon-all pipeline\n",
    "\n",
    "```bash\n",
    "# Run all the T1s\n",
    "find . -type d -maxdepth 1 -not -name '*t2' -not -name '*.log' -name 'sub*' | \\  # find all T1s\n",
    " sed 's_./__' | \\  # trim leading directory \n",
    " nohup parallel \\  # command was run remotely, so noh(ang)up.. also run in parallel\n",
    " recon-all -s {} -all -brainstem-structures -hippocampal-subfields-T1 -3T -noappend -make all -parallel -qcache \\\n",
    " > pararecon.log & # print all output to a log file\n",
    "\n",
    "# Run the special recon pipeline with the T2 weighted images\n",
    "ls -d *t2 | awk '{print $NF}' | nohup parallel recon-all -s {} -T2pial -all -brainstem-structures -hippocampal-subfields-T1 -3T -make all -qcache -noappend -parallel > pararecon-t2s.log &\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Status of Our Submitted Jobs\n",
    "\n",
    "```bash\n",
    "ps aux | grep 'recon-all'\n",
    "\n",
    "## or we can open the log file\n",
    "cd $SUBJECTS_DIR\n",
    "cat sub.01.dh.01/scripts/recon-all-status.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now what? View your results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
